奇异值分解（SVD）原理
https://blog.csdn.net/u013108511/article/details/79016939

	奇异值分解是一个有着很明显的物理意义的一种方法，
		它可以将一个比较复杂的矩阵用更小更简单的几个子矩阵的相乘来表示，这些小矩阵描述的是矩阵的重要的特性。


	就像是描述一个人一样，给别人描述说这个人长得浓眉大眼，方脸，络腮胡，而且带个黑框的眼镜，这样寥寥的几个特征，就让别人脑海里面就有一个较为清楚的认识，实际上，人脸上的特征是有着无数种的，之所以能这么描述，是因为人天生就有着非常好的抽取重要特征的能力，让机器学会抽取重要的特征，SVD是一个重要的方法。 

		所以SVD不仅是一个数学问题，在工程应用方面很多地方都有其身影，如PCA，推荐系统、任意矩阵的满秩分解。 



	矩阵的奇异值从大到小的衰减速度是非常快的，第一个奇异值就占了所有奇异值综合的93%。所以我们完全可以用第一个奇异值去代替全部的奇异值，这个方法可以扩展到非常大的矩阵SVD中，比如用前10个奇异值去代替全部的1000个奇异值，这样就可以大幅度压缩原矩阵。

奇异值分解及几何意义
https://blog.csdn.net/redline2005/article/details/24100293
	前面三个奇异值远远比后面的奇异值要大，

	我们搜集的数据中总是存在噪声：无论采用的设备多精密，方法有多好，总是会存在一些误差的。如果你们还记得上文提到的，大的奇异值对应了矩阵中的主要信息的话，运用SVD进行数据分析，提取其中的主要部分的话，还是相当合理的。



	总结：<奇异值分解之后，前几个奇异值的占据了奇异值综合的绝大部分，从统计意义上来讲，忽略误差，绝大部分信息是我们需要的，所以采用几个奇异值来取代全部实现压缩提取特征。>
		相当于PCA主成分分析。



	
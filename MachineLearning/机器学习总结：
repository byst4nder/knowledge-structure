机器学习总结：


逻辑回归通过拟合曲线（或者学习超平面）实现分类，
决策树通过寻找最佳划分特征进而学习样本路径实现分类，
支持向量机通过寻找分类超平面进而最大化类别间隔实现分类。
相比之下，朴素贝叶斯独辟蹊径，通过考虑特征概率来预测分类。

KNN投票机制：选定范围内多数服从少数。








损失函数分类：
	一、0-1损失函数
	二、平方损失函数：主要是最小二乘法OLS。
	三、绝对值损失函数
	四、对数损失函数：主要用于logistics回归与softmax分类
	五、指数损失函数：主要用于Adaboost集成学习算法
	六、铰链损失函数：主要用于支持向量机SVM中
	七、交叉熵损失函数：Cross-EntropyCost
	八、 Softmax 的损失函数


		回归问题：平方误差损失函数。
		分类问题：指数损失函数。
		决策问题：一般损失函数。

		
CNN认知：
	
	1）区别于之前的神经网络，CNN的输入层，保留了图片原有的格式：
		依然是28*28的格式！

	2）输入层每一个截取单元Local receptive fields（n*n）对应一个隐藏层神经元。
		这样隐藏层维度数量缩小到(28-n+1)*(28-n+1)，如果是n=5,就是24*24。

	3) 移动单元：stride。每次移动多少像素。

	4）共享权重和偏向（shared weights and biases）
		每个field共享同一个权重和偏向，即：卷积核相同。
			这样的好处：
				对于第一个隐藏层，所有神经元探测到同样的特征，只是根据不同位置。
				保留了图像原始的形状特征。
					共享的权重和偏向大大减少了参数的数量。
						对于一个feature map 需要n*n（比如5*5）个权重系数，加上一个偏向b，26个系数
						如果有20个feature maps，总共才26*20 = 520个参数就可以定义CNN。
							之前数量：28*28*30+30 = 23550。40倍的差距。

	5) Feature map:从输入层到输出层的映射方法不同，得到的输出不同，针对输入采用几种不同的卷积核，这样得到多个输出。。多图层。
		为何引入Feature Maps?
			Feature Map是卷积核卷出来的，而不同的特征提取（核）会提取不同的feature，模型想要达成的目的是解一个最优化，来找到能解释现象的最佳的一组卷积核。

	6）另外一层运算:Pooling layers:
		浓缩神经网聚的代表性，减少尺寸：
			在隐藏层，针对24*24的像素，再进一步浓缩：用2*2的小方框，对24*24的像素点，选取他们的最大值来输出，这样，4个值合为一个。
				变为12*12
			Pooling方法不止一种：
				L2 Pooling:平方和开方。

	总结上述过程：
		28 * 28 ===>>> 3 * 24 * 24  ===>>> 3 * 12 * 12 ===>>> 10 * 1 输出
					(3个feature maps)		(Pooling 之后)




CNN实现
	Feature maps： 实际中，对feature map选取很多，因为要多角度，多视野，全方位的观察事物，不同的特征提取（核）会提取不同的feature。

	Ensemble of network:训练多个神经网络，投票决定结果，有时准确率会提高。多数服从少数。



	为何只对最后一层使用Dropout?
		CNN本身的convolution层对于overfitting有防止作用：共享的权重造成了convolution filter强迫对于整个图像进行学习。

	为什么可以克服深度学习里面的一些困难？
		用CNN大大减少了参数数量
		用dropout减少了overfitting，
		用Retified Linear Units 代替了sigmoid,避免了overfitting，不同层学习率差别大的问题。
		用GPU计算更快，每次更新较少，但是可以训练很多次。


